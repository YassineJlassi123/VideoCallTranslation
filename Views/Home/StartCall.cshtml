@{
    ViewData["Title"] = "Video Call with Translation";
}

<h2 class="text-lg md:text-xl font-semibold text-center mb-4">Video Call with Translation</h2>

<div id="videoContainer" class="flex flex-col md:flex-row justify-center items-center mb-4">
    <video id="localVideo" autoplay muted class="w-full md:w-1/2 h-auto rounded-lg shadow-md"></video>
    <video id="remoteVideo" autoplay class="w-full md:w-1/2 h-auto rounded-lg shadow-md"></video>
</div>

<div id="translationContainer" class="max-w-lg mx-auto p-4 bg-white rounded-lg shadow-md">
    <div class="mb-4">
        <label for="sourceLang" class="block text-sm font-medium text-gray-700">Source Language:</label>
        <select id="sourceLang" class="mt-1 block w-full p-2 border border-gray-300 rounded-md shadow-sm focus:ring focus:ring-primary">
            <option value="en-US">English</option>
            <option value="es-ES">Spanish</option>
            <option value="fr-FR">French</option>
            <option value="ar-SA">Arabic</option>
            <option value="ar-TN">Tunisian Arabic</option>
            <option value="ja-JP">Japanese</option>
            <option value="ko-KR">Korean</option>
            <option value="ru-RU">Russian</option>
        </select>
    </div>
    <div class="mb-4">
        <label for="targetLang" class="block text-sm font-medium text-gray-700">Target Language:</label>
        <select id="targetLang" class="mt-1 block w-full p-2 border border-gray-300 rounded-md shadow-sm focus:ring focus:ring-primary">
            <option value="es-ES">Spanish</option>
            <option value="en-US">English</option>
            <option value="fr-FR">French</option>
            <option value="ar-SA">Arabic</option>
            <option value="ar-TN">Tunisian Arabic</option>
            <option value="ja-JP">Japanese</option>
            <option value="ko-KR">Korean</option>
            <option value="ru-RU">Russian</option>
        </select>
    </div>
    <button id="startCallBtn" class="w-full bg-blue-500 text-white p-2 rounded-md hover:bg-blue-600 transition-colors">Start Call</button>
    <div id="controlsContainer" style="display: none;" class="mt-4">
        <button id="toggleRecognition" class="w-full bg-green-500 text-white p-2 rounded-md hover:bg-green-600 transition-colors mb-2">Start Recognition</button>
        <button id="endCallBtn" class="w-full bg-red-500 text-white p-2 rounded-md hover:bg-red-600 transition-colors">End Call</button>
    </div>
    <div id="recognitionStatus" class="text-sm text-gray-600 mt-2"></div>
    <div id="translatedText" class="text-gray-600 mt-4"></div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/microsoft-signalr/8.0.0/signalr.min.js"></script>
<script src="https://webrtc.github.io/adapter/adapter-latest.js"></script>
<script>
    const roomId = '@ViewData["RoomId"]';
    let localStream;
    let peerConnection;
    let recognition;
    let isRecognizing = false;
    let lastRecognizedText = "";

    const configuration = { iceServers: [{ urls: 'stun:stun.l.google.com:19302' }] };

    const connection = new signalR.HubConnectionBuilder()
        .withUrl("/VideoCallHub")
        .build();

    async function startCall() {
        try {
            console.log("Attempting to start the call...");

            // Get video stream
            const videoStream = await navigator.mediaDevices.getUserMedia({ video: true });

            // Set the video stream
            document.getElementById('localVideo').srcObject = videoStream;
            console.log("Local video stream started");

            await connection.start();
            console.log("SignalR connection started");

            await connection.invoke("JoinRoom", roomId);
            console.log(`Joined room: ${roomId}`);

            peerConnection = new RTCPeerConnection(configuration);

            // Add video track to peer connection only
            videoStream.getTracks().forEach(track => peerConnection.addTrack(track, videoStream));
            console.log("Local video track added to peer connection");

            peerConnection.ontrack = (event) => {
                console.log("Remote stream received");
                document.getElementById('remoteVideo').srcObject = event.streams[0];
            };

            peerConnection.onicecandidate = (event) => {
                if (event.candidate) {
                    console.log("Sending ICE candidate");
                    connection.invoke("SendIceCandidate", roomId, JSON.stringify(event.candidate));
                }
            };

            const offer = await peerConnection.createOffer();
            console.log("Created offer:", offer);

            await peerConnection.setLocalDescription(offer);
            console.log("Set local description");

            await connection.invoke("SendOffer", roomId, JSON.stringify(offer));
            console.log("Sent offer");

            document.getElementById('startCallBtn').style.display = 'none';
            document.getElementById('controlsContainer').style.display = 'block';

        } catch (error) {
            console.error("Error starting the call:", error);
        }
    }

    function startSpeechRecognition() {
        navigator.mediaDevices.getUserMedia({ audio: true })
            .then((audioStream) => {
                const audioContext = new AudioContext();
                const source = audioContext.createMediaStreamSource(audioStream);

                // Create a gain node to control volume
                const gainNode = audioContext.createGain();
                gainNode.gain.value = 0; // Set gain to 0 to mute

                // Connect the source to the gain node and the gain node to the audio context's destination
                source.connect(gainNode);
                gainNode.connect(audioContext.destination); // This prevents your voice from being played back

                // Initialize the speech recognition API
                if ('webkitSpeechRecognition' in window) {
                    recognition = new webkitSpeechRecognition();
                } else if ('SpeechRecognition' in window) {
                    recognition = new SpeechRecognition();
                } else {
                    console.error("Speech recognition not supported in this browser");
                    return;
                }

                recognition.continuous = true;
                recognition.interimResults = true;
                recognition.lang = document.getElementById('sourceLang').value;

                recognition.onstart = () => {
                    console.log("Speech recognition started");
                    isRecognizing = true;
                    document.getElementById('recognitionStatus').textContent = 'Listening...';
                };

                recognition.onend = () => {
                    console.log("Speech recognition ended");
                    if (isRecognizing) {
                        recognition.start();
                    } else {
                        document.getElementById('recognitionStatus').textContent = 'Recognition ended';
                    }
                };

                recognition.onerror = (event) => {
                    console.error("Speech recognition error:", event.error);
                    document.getElementById('recognitionStatus').textContent = 'Error: ' + event.error;
                    if (event.error === 'no-speech' || event.error === 'audio-capture') {
                        restartRecognition();
                    }
                };

                recognition.onresult = async (event) => {
                    console.log("Speech recognition result:", event);

                    let interimTranscript = '';
                    let finalTranscript = '';

                    for (let i = event.resultIndex; i < event.results.length; ++i) {
                        if (event.results[i].isFinal) {
                            finalTranscript += event.results[i][0].transcript;
                        } else {
                            interimTranscript += event.results[i][0].transcript;
                        }
                    }

                    console.log("Interim transcript:", interimTranscript);
                    console.log("Final transcript:", finalTranscript);

                    if (finalTranscript && finalTranscript !== lastRecognizedText) {
                        lastRecognizedText = finalTranscript;
                        console.log("Translating text:", finalTranscript);
                        const translation = await translateText(finalTranscript);
                        console.log("Translated text:", translation);
                        document.getElementById('translatedText').textContent = translation;
                        speakTranslation(translation);
                    }
                };

                recognition.start();
            });
    }

    function restartRecognition() {
        if (isRecognizing) {
            recognition.stop();
            setTimeout(() => {
                recognition.start();
            }, 1000);
        }
    }

    function toggleRecognition() {
        const toggleButton = document.getElementById('toggleRecognition');
        if (isRecognizing) {
            isRecognizing = false;
            recognition.stop();
            toggleButton.textContent = 'Start Recognition';
        } else {
            isRecognizing = true;
            startSpeechRecognition();
            toggleButton.textContent = 'Stop Recognition';
        }
    }

    async function translateText(text) {
        const sourceLang = document.getElementById('sourceLang').value;
        const targetLang = document.getElementById('targetLang').value;

       

        try {
            const response = await fetch('/Home/Command', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({ Text: text, SourceLang: sourceLang, TargetLang: targetLang }),
            });

            if (!response.ok) {
                throw new Error("Network response was not ok");
            }

            const data = await response.json();
            console.log("Translation response:", data);
            return data.translatedText;
        } catch (error) {
            console.error("Translation error:", error);
            return "Translation failed: " + error.message;
        }
    }
    function speakTranslation(text) {
        const speech = new SpeechSynthesisUtterance(text);
        speech.lang = document.getElementById('targetLang').value;

        // This will get the audio output of the speech synthesis
        const audioContext = new (window.AudioContext || window.webkitAudioContext)();
        const mediaStreamDestination = audioContext.createMediaStreamDestination();

        speech.onstart = () => {
            console.log("Speech synthesis started");
        };

        speech.onend = () => {
            console.log("Speech synthesis ended");
        };

        speech.onerror = (event) => {
            console.error("Speech synthesis error:", event.error);
        };

        // Connect the SpeechSynthesis API to the MediaStreamDestination
        const source = audioContext.createGain();
        source.connect(mediaStreamDestination);

        // Start speech synthesis
        speechSynthesis.speak(speech);

        // Create a stream from the destination
        const translatedAudioStream = mediaStreamDestination.stream;

        // Send the translated audio stream to the remote peer
        translatedAudioStream.getTracks().forEach(track => {
            peerConnection.addTrack(track, translatedAudioStream);
        });

        console.log("Translated audio track added to peer connection");
    }


    document.getElementById('startCallBtn').addEventListener('click', startCall);
    document.getElementById('toggleRecognition').addEventListener('click', toggleRecognition);
    document.getElementById('endCallBtn').addEventListener('click', endCall);

    async function endCall() {
        console.log("Ending call...");
        if (recognition) {
            recognition.stop();
        }
        await connection.stop();
        if (peerConnection) {
            peerConnection.close();
        }
        console.log("Call ended");
        document.getElementById('controlsContainer').style.display = 'none';
        document.getElementById('startCallBtn').style.display = 'block';
    }

    connection.on("ReceiveOffer", async (offer) => {
        console.log("Received offer:", offer);
        await peerConnection.setRemoteDescription(new RTCSessionDescription(JSON.parse(offer)));

        const answer = await peerConnection.createAnswer();
        await peerConnection.setLocalDescription(answer);
        await connection.invoke("SendAnswer", roomId, JSON.stringify(answer));
    });

    connection.on("ReceiveAnswer", async (answer) => {
        console.log("Received answer:", answer);
        await peerConnection.setRemoteDescription(new RTCSessionDescription(JSON.parse(answer)));
    });

    connection.on("ReceiveIceCandidate", async (candidate) => {
        console.log("Received ICE candidate:", candidate);
        await peerConnection.addIceCandidate(new RTCIceCandidate(JSON.parse(candidate)));
    });
</script>
